{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credit.pkl', 'rb')  as f:\n",
    "    X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('census.pkl', 'rb')  as f:\n",
    "    X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy Score\n",
       "SVM                            0.988\n",
       "K-Nearest Neighbors            0.986\n",
       "Random Forest                  0.984\n",
       "Decision Tree                  0.984\n",
       "Logistic Regression            0.946\n",
       "Gaussian Naive Bayes           0.938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmos = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=1),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=40, criterion='entropy', random_state=0),\n",
    "    'Decision Tree': DecisionTreeClassifier(criterion='entropy'),\n",
    "    'SVM':SVC(kernel='rbf', random_state=1, C=2.0),\n",
    "    # 'Rede_Neural':  MLPClassifier(max_iter=1500, verbose=True, tol=0.0000100, \n",
    "    #                                solver='adam', activation='relu', \n",
    "    #                                hidden_layer_sizes=(2, 2) )\n",
    "}\n",
    "\n",
    "# DataFrame para armazenar os resultados\n",
    "resultados_credit = pd.DataFrame(index=['Accuracy Score'])\n",
    "\n",
    "for nome, modelo in algoritmos.items():\n",
    "    # Treinamento do modelo\n",
    "    modelo.fit(X_credit_treinamento, y_credit_treinamento)\n",
    "    \n",
    "    # Predição\n",
    "    previsoes = modelo.predict(X_credit_teste)\n",
    "    \n",
    "    # Cálculo do accuracy_score\n",
    "    accuracy = accuracy_score(y_credit_teste, previsoes)\n",
    "    \n",
    "    # Armazenar o resultado na DataFrame de resultados\n",
    "    resultados_credit[nome] = accuracy\n",
    "\n",
    "# Exibir os resultados\n",
    "resultados_credit.T.sort_values(by='Accuracy Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CURSOS\\UDEMY\\Machine Learning com Python\\codigos\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] O sistema não pode encontrar o arquivo especificado\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"d:\\CURSOS\\UDEMY\\Machine Learning com Python\\codigos\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.849744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.822313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.476766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.847697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.813306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.848516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy_score\n",
       "Logistic Regression         0.849744\n",
       "K-Nearest Neighbors         0.822313\n",
       "Gaussian Naive Bayes        0.476766\n",
       "Random Forest               0.847697\n",
       "Decision Tree               0.813306\n",
       "SVM                         0.848516"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmos = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=1),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=40, criterion='entropy', random_state=0),\n",
    "    'Decision Tree': DecisionTreeClassifier(criterion='entropy'),\n",
    "    'SVM':SVC(kernel='rbf', random_state=1, C=2.0),\n",
    "    # 'rede_neural_census': MLPClassifier(verbose=True, \n",
    "    #                                max_iter=1000,\n",
    "    #                                tol=0.000010,\n",
    "    #                                hidden_layer_sizes=(55,55))\n",
    "}\n",
    "\n",
    "resultados_census = pd.DataFrame(index=['Accuracy_score'])\n",
    "\n",
    "for nome, modelo in algoritmos.items():\n",
    "    modelo.fit(X_census_treinamento, y_census_treinamento)\n",
    "\n",
    "    previsoes = modelo.predict(X_census_teste)\n",
    "\n",
    "    accuracy = accuracy_score(y_census_teste, previsoes)\n",
    "\n",
    "    resultados_census[nome] = accuracy\n",
    "\n",
    "resultados_census.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parametros = {'criterion': ['gini', 'entropy'],\n",
    "#               'splitter': ['best', 'random'],\n",
    "#               'min_samples_split': [2, 5, 10],\n",
    "#               'min_samples_leaf': [1, 5, 10]}\n",
    "\n",
    "# # Instanciando o DecisionTreeClassifier\n",
    "# estimator = DecisionTreeClassifier()\n",
    "\n",
    "# # Criando a GridSearchCV com o estimator e os parâmetros\n",
    "# grid_search = GridSearchCV(estimator=estimator, param_grid=parametros)\n",
    "\n",
    "# # Realizando o fit com os dados\n",
    "# grid_search.fit(X_credit, y_credit)\n",
    "\n",
    "# # Obtendo os melhores parâmetros e resultado\n",
    "# melhores_parametros = grid_search.best_params_\n",
    "# melhor_resultado = grid_search.best_score_\n",
    "\n",
    "# # Imprimindo os resultados\n",
    "# print(melhores_parametros)\n",
    "# print(melhor_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_credit = np.concatenate(((X_credit_treinamento, X_credit_teste)), axis=0)\n",
    "y_credit = np.concatenate(((y_credit_treinamento, y_credit_teste)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando GridSearchCV para Logistic Regression...\n",
      "Melhores parâmetros para Logistic Regression: {'C': 1, 'max_iter': 100, 'solver': 'newton-cg'}\n",
      "Melhor resultado para Logistic Regression: 0.9484999999999999\n",
      "\n",
      "Realizando GridSearchCV para K-Nearest Neighbors...\n",
      "Melhores parâmetros para K-Nearest Neighbors: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "Melhor resultado para K-Nearest Neighbors: 0.9804999999999999\n",
      "\n",
      "Realizando GridSearchCV para Gaussian Naive Bayes...\n",
      "Melhores parâmetros para Gaussian Naive Bayes: {'var_smoothing': 1e-09}\n",
      "Melhor resultado para Gaussian Naive Bayes: 0.9255000000000001\n",
      "\n",
      "Realizando GridSearchCV para Random Forest...\n",
      "Melhores parâmetros para Random Forest: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Melhor resultado para Random Forest: 0.9865\n",
      "\n",
      "Realizando GridSearchCV para Decision Tree...\n",
      "Melhores parâmetros para Decision Tree: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Melhor resultado para Decision Tree: 0.983\n",
      "\n",
      "Realizando GridSearchCV para SVM...\n",
      "Melhores parâmetros para SVM: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Melhor resultado para SVM: 0.9870000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Definindo os parâmetros para cada algoritmo\n",
    "parametros = {\n",
    "    'Logistic Regression': {\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'Gaussian Naive Bayes': {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 5, 10]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 5, 10]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    # 'Rede Neural': {\n",
    "    #     'hidden_layer_sizes': [(50,), (100,), (50,50)],\n",
    "    #     'activation': ['relu', 'tanh'],\n",
    "    #     'solver': ['adam', 'sgd'],\n",
    "    #     'max_iter': [200, 400]\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Definindo os estimadores para cada algoritmo\n",
    "estimadores = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    # 'Rede Neural': MLPClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Iterando pelos algoritmos e realizando a busca dos melhores parâmetros\n",
    "for nome, estimator in estimadores.items():\n",
    "    print(f\"Realizando GridSearchCV para {nome}...\")\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=parametros[nome])\n",
    "    grid_search.fit(X_credit, y_credit)\n",
    "    \n",
    "    melhores_parametros = grid_search.best_params_\n",
    "    melhor_resultado = grid_search.best_score_\n",
    "    \n",
    "    print(f\"Melhores parâmetros para {nome}: {melhores_parametros}\")\n",
    "    print(f\"Melhor resultado para {nome}: {melhor_resultado}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "resultados_arvore = []\n",
    "resultados_regressao = []\n",
    "resultados_knn = []\n",
    "resultados_randon_forest = []\n",
    "resultados_svm = []\n",
    "#resultados_rede_neural = []\n",
    "\n",
    "for i in range(30):\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "    arvore = DecisionTreeClassifier(criterion = 'entropy', min_samples_leaf =  1, min_samples_split =  5, splitter = 'best')\n",
    "    scores = cross_val_score(arvore, X_credit, y_credit, cv = kfold)\n",
    "    regressao = LogisticRegression(C= 1, max_iter=100, solver= 'newton-cg')\n",
    "    scores_reg = cross_val_score(regressao, X_credit, y_credit, cv=kfold)\n",
    "    kmeans = KNeighborsClassifier(metric = 'manhattan', n_neighbors = 7, weights= 'distance')\n",
    "    scores_knn= cross_val_score(kmeans, X_credit, y_credit, cv=kfold)\n",
    "    random_forest = RandomForestClassifier(criterion='entropy', min_samples_leaf = 1, min_samples_split= 5, n_estimators= 100)\n",
    "    scores_rf = cross_val_score(random_forest, X_credit, y_credit, cv=kfold)\n",
    "    svm = SVC(C =10, gamma= 'scale', kernel = 'rbf')\n",
    "    scores_svm = cross_val_score(svm, X_credit, y_credit, cv=kfold)\n",
    "    # rede = MLPClassifier()\n",
    "    # score_rn = cross_val_score(rede, X_credit, y_credit, cv=kfold)\n",
    "    # print(scores)\n",
    "    # print(scores.mean())\n",
    "    resultados_arvore.append(scores.mean())\n",
    "    resultados_regressao.append(scores_reg.mean())\n",
    "    resultados_knn.append(scores_reg.mean())\n",
    "    resultados_randon_forest.append(scores_rf.mean())\n",
    "    resultados_svm.append(scores_svm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arvore</th>\n",
       "      <th>regressao</th>\n",
       "      <th>Random forest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Arvore  regressao  Random forest     KNN     SVM\n",
       "0   0.9865     0.9475         0.9865  0.9475  0.9915\n",
       "1   0.9845     0.9465         0.9875  0.9465  0.9890\n",
       "2   0.9905     0.9470         0.9890  0.9470  0.9910\n",
       "3   0.9875     0.9460         0.9870  0.9460  0.9890\n",
       "4   0.9880     0.9465         0.9895  0.9465  0.9890\n",
       "5   0.9885     0.9465         0.9885  0.9465  0.9880\n",
       "6   0.9880     0.9470         0.9865  0.9470  0.9895\n",
       "7   0.9875     0.9480         0.9870  0.9480  0.9885\n",
       "8   0.9870     0.9465         0.9880  0.9465  0.9875\n",
       "9   0.9870     0.9465         0.9885  0.9465  0.9895\n",
       "10  0.9865     0.9475         0.9865  0.9475  0.9885\n",
       "11  0.9900     0.9475         0.9890  0.9475  0.9895\n",
       "12  0.9885     0.9475         0.9860  0.9475  0.9880\n",
       "13  0.9865     0.9475         0.9865  0.9475  0.9890\n",
       "14  0.9850     0.9485         0.9865  0.9485  0.9910\n",
       "15  0.9860     0.9475         0.9860  0.9475  0.9875\n",
       "16  0.9855     0.9460         0.9870  0.9460  0.9890\n",
       "17  0.9905     0.9470         0.9895  0.9470  0.9910\n",
       "18  0.9875     0.9465         0.9885  0.9465  0.9895\n",
       "19  0.9870     0.9465         0.9865  0.9465  0.9890\n",
       "20  0.9830     0.9465         0.9855  0.9465  0.9880\n",
       "21  0.9870     0.9470         0.9885  0.9470  0.9915\n",
       "22  0.9885     0.9455         0.9865  0.9455  0.9890\n",
       "23  0.9875     0.9465         0.9875  0.9465  0.9885\n",
       "24  0.9880     0.9470         0.9880  0.9470  0.9895\n",
       "25  0.9885     0.9470         0.9880  0.9470  0.9890\n",
       "26  0.9880     0.9475         0.9880  0.9475  0.9875\n",
       "27  0.9855     0.9465         0.9845  0.9465  0.9910\n",
       "28  0.9860     0.9480         0.9850  0.9480  0.9865\n",
       "29  0.9875     0.9465         0.9890  0.9465  0.9890"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = pd.DataFrame({'Arvore': resultados_arvore,\n",
    "                       'regressao': resultados_regressao,\n",
    "                       'Random forest': resultados_randon_forest,\n",
    "                       'KNN': resultados_knn,\n",
    "                       'SVM': resultados_svm\n",
    "                       })\n",
    "resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
